{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a5eb5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, numpy as np\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a618892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "35c8e7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ade2b790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4842f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update 28x28 image to 1 vector of length 784\n",
    "# divide by 255 to normalize values between 0-1 (original values were 0-255)\n",
    "images, labels = (x_train[0:1000].reshape(1000, 28*28) / 255, y_train[0:1000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "089415f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "555b39ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 784)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "66fe8038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1bf5018d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0,\n",
       "       9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
       "       3, 9, 8, 5, 9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5,\n",
       "       6, 1, 0, 0, 1, 7, 1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9,\n",
       "       0, 4, 6, 7, 4, 6, 8, 0, 7, 8, 3, 1, 5, 7, 1, 7, 1, 1, 6, 3, 0, 2,\n",
       "       9, 3, 1, 1, 0, 4, 9, 2, 0, 0, 2, 0, 2, 7, 1, 8, 6, 4, 1, 6, 3, 4,\n",
       "       5, 9, 1, 3, 3, 8, 5, 4, 7, 7, 4, 2, 8, 5, 8, 6, 7, 3, 4, 6, 1, 9,\n",
       "       9, 6, 0, 3, 7, 2, 8, 2, 9, 4, 4, 6, 4, 9, 7, 0, 9, 2, 9, 5, 1, 5,\n",
       "       9, 1, 2, 3, 2, 3, 5, 9, 1, 7, 6, 2, 8, 2, 2, 5, 0, 7, 4, 9, 7, 8,\n",
       "       3, 2, 1, 1, 8, 3, 6, 1, 0, 3, 1, 0, 0, 1, 7, 2, 7, 3, 0, 4, 6, 5,\n",
       "       2, 6, 4, 7, 1, 8, 9, 9, 3, 0, 7, 1, 0, 2, 0, 3, 5, 4, 6, 5, 8, 6,\n",
       "       3, 7, 5, 8, 0, 9, 1, 0, 3, 1, 2, 2, 3, 3, 6, 4, 7, 5, 0, 6, 2, 7,\n",
       "       9, 8, 5, 9, 2, 1, 1, 4, 4, 5, 6, 4, 1, 2, 5, 3, 9, 3, 9, 0, 5, 9,\n",
       "       6, 5, 7, 4, 1, 3, 4, 0, 4, 8, 0, 4, 3, 6, 8, 7, 6, 0, 9, 7, 5, 7,\n",
       "       2, 1, 1, 6, 8, 9, 4, 1, 5, 2, 2, 9, 0, 3, 9, 6, 7, 2, 0, 3, 5, 4,\n",
       "       3, 6, 5, 8, 9, 5, 4, 7, 4, 2, 7, 3, 4, 8, 9, 1, 9, 2, 8, 7, 9, 1,\n",
       "       8, 7, 4, 1, 3, 1, 1, 0, 2, 3, 9, 4, 9, 2, 1, 6, 8, 4, 7, 7, 4, 4,\n",
       "       9, 2, 5, 7, 2, 4, 4, 2, 1, 9, 7, 2, 8, 7, 6, 9, 2, 2, 3, 8, 1, 6,\n",
       "       5, 1, 1, 0, 2, 6, 4, 5, 8, 3, 1, 5, 1, 9, 2, 7, 4, 4, 4, 8, 1, 5,\n",
       "       8, 9, 5, 6, 7, 9, 9, 3, 7, 0, 9, 0, 6, 6, 2, 3, 9, 0, 7, 5, 4, 8,\n",
       "       0, 9, 4, 1, 2, 8, 7, 1, 2, 6, 1, 0, 3, 0, 1, 1, 8, 2, 0, 3, 9, 4,\n",
       "       0, 5, 0, 6, 1, 7, 7, 8, 1, 9, 2, 0, 5, 1, 2, 2, 7, 3, 5, 4, 9, 7,\n",
       "       1, 8, 3, 9, 6, 0, 3, 1, 1, 2, 6, 3, 5, 7, 6, 8, 3, 9, 5, 8, 5, 7,\n",
       "       6, 1, 1, 3, 1, 7, 5, 5, 5, 2, 5, 8, 7, 0, 9, 7, 7, 5, 0, 9, 0, 0,\n",
       "       8, 9, 2, 4, 8, 1, 6, 1, 6, 5, 1, 8, 3, 4, 0, 5, 5, 8, 3, 6, 2, 3,\n",
       "       9, 2, 1, 1, 5, 2, 1, 3, 2, 8, 7, 3, 7, 2, 4, 6, 9, 7, 2, 4, 2, 8,\n",
       "       1, 1, 3, 8, 4, 0, 6, 5, 9, 3, 0, 9, 2, 4, 7, 1, 2, 9, 4, 2, 6, 1,\n",
       "       8, 9, 0, 6, 6, 7, 9, 9, 8, 0, 1, 4, 4, 6, 7, 1, 5, 7, 0, 3, 5, 8,\n",
       "       4, 7, 1, 2, 5, 9, 5, 6, 7, 5, 9, 8, 8, 3, 6, 9, 7, 0, 7, 5, 7, 1,\n",
       "       1, 0, 7, 9, 2, 3, 7, 3, 2, 4, 1, 6, 2, 7, 5, 5, 7, 4, 0, 2, 6, 3,\n",
       "       6, 4, 0, 4, 2, 6, 0, 0, 0, 0, 3, 1, 6, 2, 2, 3, 1, 4, 1, 5, 4, 6,\n",
       "       4, 7, 2, 8, 7, 9, 2, 0, 5, 1, 4, 2, 8, 3, 2, 4, 1, 5, 4, 6, 0, 7,\n",
       "       9, 8, 4, 9, 8, 0, 1, 1, 0, 2, 2, 3, 2, 4, 4, 5, 8, 6, 5, 7, 7, 8,\n",
       "       8, 9, 7, 4, 7, 3, 2, 0, 8, 6, 8, 6, 1, 6, 8, 9, 4, 0, 9, 0, 4, 1,\n",
       "       5, 4, 7, 5, 3, 7, 4, 9, 8, 5, 8, 6, 3, 8, 6, 9, 9, 1, 8, 3, 5, 8,\n",
       "       6, 5, 9, 7, 2, 5, 0, 8, 5, 1, 1, 0, 9, 1, 8, 6, 7, 0, 9, 3, 0, 8,\n",
       "       8, 9, 6, 7, 8, 4, 7, 5, 9, 2, 6, 7, 4, 5, 9, 2, 3, 1, 6, 3, 9, 2,\n",
       "       2, 5, 6, 8, 0, 7, 7, 1, 9, 8, 7, 0, 9, 9, 4, 6, 2, 8, 5, 1, 4, 1,\n",
       "       5, 5, 1, 7, 3, 6, 4, 3, 2, 5, 6, 4, 4, 0, 4, 4, 6, 7, 2, 4, 3, 3,\n",
       "       8, 0, 0, 3, 2, 2, 9, 8, 2, 3, 7, 0, 1, 1, 0, 2, 3, 3, 8, 4, 3, 5,\n",
       "       7, 6, 4, 7, 7, 8, 5, 9, 7, 0, 3, 1, 6, 2, 4, 3, 4, 4, 7, 5, 9, 6,\n",
       "       9, 0, 7, 1, 4, 2, 7, 3, 6, 7, 5, 8, 4, 5, 5, 2, 7, 1, 1, 5, 6, 8,\n",
       "       5, 8, 4, 0, 7, 9, 9, 2, 9, 7, 7, 8, 7, 4, 2, 6, 9, 1, 7, 0, 6, 4,\n",
       "       2, 5, 7, 0, 7, 1, 0, 3, 7, 6, 5, 0, 6, 1, 5, 1, 7, 8, 5, 0, 3, 4,\n",
       "       7, 7, 5, 7, 8, 6, 9, 3, 8, 6, 1, 0, 9, 7, 1, 3, 0, 5, 6, 4, 4, 2,\n",
       "       4, 4, 3, 1, 7, 7, 6, 0, 3, 6], dtype=uint8)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "94afc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = np.zeros((len(labels), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "56113faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "73a40883",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,l in enumerate(labels): #update labels... w/ one-hot encoding\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ea60ed87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c8e31961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0] # 1 in 5 location now b/c 5 was the first value in labels previously (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "949774b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = x_test.reshape(len(x_test),28*28) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e23fe368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d9f8df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.zeros((len(y_test),10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "599ea06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,l in enumerate(y_test): #one-hot encoding...\n",
    "    test_labels[i][l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "61bc69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "relu = lambda x:(x>=0) * x\n",
    "relu2deriv = lambda x: x>=0\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = \\\n",
    "    (0.005, 350, 40, 784, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "864418b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "# we only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e65d2710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 40)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_0_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0331e024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0165956 ,  0.0440649 , -0.09997713, -0.03953349, -0.07064882,\n",
       "       -0.08153228, -0.06274796, -0.03088785, -0.02064651,  0.00776335,\n",
       "       -0.0161611 ,  0.0370439 , -0.05910955,  0.07562349, -0.09452248,\n",
       "        0.0340935 , -0.01653904,  0.01173797, -0.07192261, -0.0603797 ,\n",
       "        0.06014891,  0.09365232, -0.03731516,  0.03846452,  0.07527783,\n",
       "        0.07892133, -0.08299116, -0.09218904, -0.06603392,  0.0756285 ,\n",
       "       -0.08033063, -0.01577847,  0.09157791,  0.00663306,  0.03837542,\n",
       "       -0.03689687,  0.03730019,  0.06692513, -0.09634234,  0.05002886])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_0_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "da947924",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels)) - 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bc99c38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I:349 Error:[[0.0 Correct:1.099"
     ]
    }
   ],
   "source": [
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        error += ((labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
    "        \n",
    "        layer_2_delta = labels[i:i+1] - layer_2\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)*relu2deriv(layer_1)\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    sys.stdout.write(\"\\r\"+ \\\n",
    "                     \" I:\"+str(j)+ \\\n",
    "                     \" Error:\"+str(error/float(len(images)))[0:5] + \\\n",
    "                     \" Correct:\" + str(correct_cnt/float(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ca3d4e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do we do on an image we haven't seen before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "72f92634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test-Err:0.653 Test-Acc:0.7073\n"
     ]
    }
   ],
   "source": [
    "if(j % 10 == 0 or j == iterations-1):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(len(test_images)):\n",
    "        layer_0 = test_images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        error += np.sum((test_labels[i:i+1] - layer_2)**2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "    \n",
    "    sys.stdout.write(\" Test-Err:\" + str(error/float(len(test_images)))[0:5] + \\\n",
    "                     \" Test-Acc:\" + str(correct_cnt/float(len(test_images))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "727c93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "26d5aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can view the weights of a NN as a high dimensional shape - shape molds around data as we train. slight diff in shape\n",
    "# can result in bad prediction\n",
    "\n",
    "# regularization is a subfield of methods for getting a model to genearlize to new datapoints (instead of just memorizing\n",
    "# training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "76712490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# industry standard regularization: dropout\n",
    "#    during training randomly set neurons in the network to 0. this causes the nn to train exclusively using \n",
    "#    random subsections of the network. Dropout makes a big network acct like a little one by randomly training\n",
    "#    subsections of the network at a time - little networks don't overfit. smaller networks have less \n",
    "#    \"expresive power\" - they can't latch on to more granular details (noise) that can cause overfitting.\n",
    "#    only have room to capture big obvious high-level features.\n",
    "\n",
    "# basically a form of training a bunch of networks and averaging them.\n",
    "\n",
    "# if you train 100 nns (all initialized randomly) they will tend to latch onto different noise but similar broad signal\n",
    "# thus when they make mistakes they will make differing mistakes, and these differing mistakes tend to cancel out\n",
    "# revealing the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a31dafae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i:0 test-err:0.65217 test-acc:0.6492 train-err:0.91715 train-acc:0.389\n",
      "i:10 test-err:0.44305 test-acc:0.7971 train-err:0.44493 train-acc:0.806\n",
      "i:20 test-err:0.41669 test-acc:0.8201 train-err:0.42812 train-acc:0.826\n",
      "i:30 test-err:0.41382 test-acc:0.8157 train-err:0.39975 train-acc:0.839\n",
      "i:40 test-err:0.41227 test-acc:0.8276 train-err:0.39331 train-acc:0.837\n",
      "i:50 test-err:0.409 test-acc:0.827 train-err:0.37683 train-acc:0.851\n",
      "i:60 test-err:0.40459 test-acc:0.8284 train-err:0.36824 train-acc:0.878\n",
      "i:70 test-err:0.39275 test-acc:0.8345 train-err:0.35609 train-acc:0.867\n",
      "i:80 test-err:0.39578 test-acc:0.8309 train-err:0.35862 train-acc:0.877\n",
      "i:90 test-err:0.39184 test-acc:0.828 train-err:0.34455 train-acc:0.879\n",
      "i:100 test-err:0.3931 test-acc:0.8268 train-err:0.34609 train-acc:0.893\n",
      "i:110 test-err:0.40145 test-acc:0.826 train-err:0.34037 train-acc:0.883\n",
      "i:120 test-err:0.39769 test-acc:0.8261 train-err:0.33537 train-acc:0.888\n",
      "i:130 test-err:0.39774 test-acc:0.8273 train-err:0.33964 train-acc:0.898\n",
      "i:140 test-err:0.39504 test-acc:0.821 train-err:0.31772 train-acc:0.904\n",
      "i:150 test-err:0.40068 test-acc:0.8195 train-err:0.3252 train-acc:0.892\n",
      "i:160 test-err:0.39103 test-acc:0.8134 train-err:0.32396 train-acc:0.9\n",
      "i:170 test-err:0.39718 test-acc:0.8217 train-err:0.3175 train-acc:0.902\n",
      "i:180 test-err:0.39435 test-acc:0.8241 train-err:0.31013 train-acc:0.906\n",
      "i:190 test-err:0.3986 test-acc:0.8151 train-err:0.30492 train-acc:0.907\n",
      "i:200 test-err:0.39504 test-acc:0.8174 train-err:0.30725 train-acc:0.912\n",
      "i:210 test-err:0.39958 test-acc:0.8211 train-err:0.2979 train-acc:0.911\n",
      "i:220 test-err:0.39449 test-acc:0.8197 train-err:0.30179 train-acc:0.897\n",
      "i:230 test-err:0.39368 test-acc:0.8171 train-err:0.29433 train-acc:0.902\n",
      "i:240 test-err:0.40119 test-acc:0.8153 train-err:0.28956 train-acc:0.921\n",
      "i:250 test-err:0.39876 test-acc:0.8211 train-err:0.29142 train-acc:0.921\n",
      "i:260 test-err:0.39542 test-acc:0.8176 train-err:0.27958 train-acc:0.928\n",
      "i:270 test-err:0.40174 test-acc:0.8155 train-err:0.29175 train-acc:0.928\n",
      "i:280 test-err:0.39503 test-acc:0.8204 train-err:0.28489 train-acc:0.929\n",
      "i:290 test-err:0.40193 test-acc:0.8213 train-err:0.28208 train-acc:0.927"
     ]
    }
   ],
   "source": [
    "# with dropout\n",
    "        #     randomly turn off nodes and multiply by 2 b/c sum was cut in half by all the off nodes\n",
    "        #     we want \"volume\" of layer_1 to be the same between training and testing despite dropout\n",
    "\n",
    "alpha, iterations, hidden_size = (0.005, 300, 100)\n",
    "pixels_per_image, num_labels = (784, 10)\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape) # \n",
    "        layer_1 *= dropout_mask * 2 # dropout\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
    "        \n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)*relu2deriv(layer_1)\n",
    "        # DROPOUT AGAIN\n",
    "        layer_1_delta *= dropout_mask\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    if (j%10 == 0):\n",
    "        test_error = 0.0\n",
    "        test_correct_cnt = 0\n",
    "        \n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_2)\n",
    "            \n",
    "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "            \n",
    "        sys.stdout.write(\n",
    "            f\"\\ni:{j}\"\n",
    "            f\" test-err:{test_error/float(len(test_images)):.5}\"\n",
    "            f\" test-acc:{test_correct_cnt/float(len(test_images))}\"\n",
    "            f\" train-err:{error/float(len(images)):.5}\"\n",
    "            f\" train-acc:{correct_cnt/float(len(images))}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d0c64dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 81% test-acc compared to 71% without dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "67b37a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i:0 test-err:0.0 test-acc:0.0 train-err:1.2041 train-acc:0.171\n",
      "i:10 test-err:0.0 test-acc:0.0 train-err:0.57557 train-acc:0.717\n",
      "i:20 test-err:0.0 test-acc:0.0 train-err:0.50938 train-acc:0.755\n",
      "i:30 test-err:0.0 test-acc:0.0 train-err:0.47461 train-acc:0.769\n",
      "i:40 test-err:0.0 test-acc:0.0 train-err:0.44688 train-acc:0.797\n",
      "i:50 test-err:0.0 test-acc:0.0 train-err:0.44398 train-acc:0.789\n",
      "i:60 test-err:0.0 test-acc:0.0 train-err:0.42499 train-acc:0.822\n",
      "i:70 test-err:0.0 test-acc:0.0 train-err:0.4269 train-acc:0.809\n",
      "i:80 test-err:0.0 test-acc:0.0 train-err:0.42301 train-acc:0.814\n",
      "i:90 test-err:0.0 test-acc:0.0 train-err:0.42454 train-acc:0.811\n",
      "i:100 test-err:0.0 test-acc:0.0 train-err:0.40636 train-acc:0.844\n",
      "i:110 test-err:0.0 test-acc:0.0 train-err:0.4042 train-acc:0.832\n",
      "i:120 test-err:0.0 test-acc:0.0 train-err:0.40836 train-acc:0.837\n",
      "i:130 test-err:0.0 test-acc:0.0 train-err:0.40343 train-acc:0.83\n",
      "i:140 test-err:0.0 test-acc:0.0 train-err:0.39914 train-acc:0.839\n",
      "i:150 test-err:0.0 test-acc:0.0 train-err:0.39566 train-acc:0.837\n",
      "i:160 test-err:0.0 test-acc:0.0 train-err:0.39402 train-acc:0.842\n",
      "i:170 test-err:0.0 test-acc:0.0 train-err:0.39917 train-acc:0.837\n",
      "i:180 test-err:0.0 test-acc:0.0 train-err:0.39711 train-acc:0.833\n",
      "i:190 test-err:0.0 test-acc:0.0 train-err:0.38844 train-acc:0.849\n",
      "i:200 test-err:0.0 test-acc:0.0 train-err:0.39669 train-acc:0.828\n",
      "i:210 test-err:0.0 test-acc:0.0 train-err:0.40434 train-acc:0.851\n",
      "i:220 test-err:0.0 test-acc:0.0 train-err:0.40091 train-acc:0.857\n",
      "i:230 test-err:0.0 test-acc:0.0 train-err:0.38058 train-acc:0.851\n",
      "i:240 test-err:0.0 test-acc:0.0 train-err:0.38681 train-acc:0.843\n",
      "i:250 test-err:0.0 test-acc:0.0 train-err:0.37559 train-acc:0.854\n",
      "i:260 test-err:0.0 test-acc:0.0 train-err:0.37371 train-acc:0.857\n",
      "i:270 test-err:0.0 test-acc:0.0 train-err:0.38793 train-acc:0.846\n",
      "i:280 test-err:0.0 test-acc:0.0 train-err:0.3688 train-acc:0.87\n",
      "i:290 test-err:0.0 test-acc:0.0 train-err:0.36162 train-acc:0.872"
     ]
    }
   ],
   "source": [
    "# batch gradient descent\n",
    "#     instead of training on 1 example at a time let's train 100 training examples at a time and average the weight updates\n",
    "#     among all 100 examples.\n",
    "\n",
    "batch_size = 100\n",
    "alpha, iterations = (0.001, 300)\n",
    "pixels_per_image, num_labels, hidden_size = (784, 10, 100)\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(int(len(images) / batch_size)):\n",
    "        batch_start, batch_end = ((i * batch_size), ((i+1)*batch_size))\n",
    "        \n",
    "        layer_0 = images[batch_start:batch_end]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        error += np.sum((labels[batch_start:batch_end] - layer_2) ** 2)\n",
    "        for k in range(batch_size):\n",
    "            correct_cnt += int(np.argmax(layer_2[k:k+1]) == \\\n",
    "                np.argmax(labels[batch_start+k:batch_start+k+1]))\n",
    "            \n",
    "            layer_2_delta = (labels[batch_start:batch_end]-layer_2) / batch_size \n",
    "                                                        \n",
    "            layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "            layer_1_delta *= dropout_mask\n",
    "            \n",
    "            weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "            weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "            \n",
    "    if(j%10 == 0):\n",
    "        test_error = 0.0\n",
    "        test_correct_cnt = 0 \n",
    "        \n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_2)\n",
    "            \n",
    "        sys.stdout.write(\n",
    "            f\"\\ni:{j}\"\n",
    "            f\" test-err:{test_error/float(len(test_images)):.5}\"\n",
    "            f\" test-acc:{test_correct_cnt/float(len(test_images))}\"\n",
    "            f\" train-err:{error/float(len(images)):.5}\"\n",
    "            f\" train-acc:{correct_cnt/float(len(images))}\"\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ecf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoother training accuracy. individual training examples are very noisy in terms of the weight updates they generate\n",
    "# averaging them makes for smoother learning process. b/c it takes an average it can take bigger steps.\n",
    "# generally researchers pick numbers randomly until they find a batch_size/alpha pair that \"seems to work well\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grokking",
   "language": "python",
   "name": "grokking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
